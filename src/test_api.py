import time
import requests
from openai import OpenAI

# --- Cáº¤U HÃŒNH ---
API_KEY = "mysecretkey"
BASE_URL = "http://100.96.1.73:8500/v1"
MODEL_NAME = "meta-llama/Meta-Llama-3-8B-Instruct"

def check_server_connection():
    """Kiá»ƒm tra xem server vLLM cÃ³ Ä‘ang pháº£n há»“i khÃ´ng trÆ°á»›c khi chat"""
    print(f"ğŸ” Äang kiá»ƒm tra káº¿t ná»‘i tá»›i server táº¡i {BASE_URL}...")
    try:
        # Thá»­ láº¥y danh sÃ¡ch model Ä‘á»ƒ kiá»ƒm tra káº¿t ná»‘i
        response = requests.get(f"{BASE_URL}/models", headers={"Authorization": f"Bearer {API_KEY}"}, timeout=10)
        if response.status_code == 200:
            print("âœ… Káº¿t ná»‘i thÃ nh cÃ´ng! Server Ä‘Ã£ sáºµn sÃ ng.")
            return True
        else:
            print(f"âŒ Server pháº£n há»“i lá»—i: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ KhÃ´ng thá»ƒ káº¿t ná»‘i tá»›i server. HÃ£y cháº¯c cháº¯n báº¡n Ä‘Ã£ cháº¡y vLLM.\nChi tiáº¿t: {e}")
        return False

def start_chat():
    # Khá»Ÿi táº¡o client vá»›i timeout lá»›n (300 giÃ¢y) Ä‘á»ƒ xá»­ lÃ½ Cold Start trÃªn H200
    client = OpenAI(
        base_url=BASE_URL,
        api_key=API_KEY,
        timeout=300.0  
    )

    messages = [
        {"role": "system", "content": "Báº¡n lÃ  trá»£ lÃ½ AI chuyÃªn gia vá» nÃ´ng nghiá»‡p. HÃ£y tráº£ lá»i chuyÃªn nghiá»‡p."}
    ]

    print("\n--- Báº®T Äáº¦U TRÃ’ CHUYá»†N (GÃµ 'exit' Ä‘á»ƒ thoÃ¡t) ---")
    print("LÆ°u Ã½: CÃ¢u há»i Ä‘áº§u tiÃªn cÃ³ thá»ƒ máº¥t 1-2 phÃºt Ä‘á»ƒ server biÃªn dá»‹ch CUDA Graph.")

    while True:
        user_input = input("\nğŸ‘¤ Báº¡n: ")
        if user_input.lower() in ["exit", "quit", "thoÃ¡t"]:
            break
        if not user_input.strip():
            continue

        messages.append({"role": "user", "content": user_input})
        print("ğŸ¤– AI: ", end="", flush=True)

        try:
            # Sá»­ dá»¥ng stream Ä‘á»ƒ tháº¥y chá»¯ cháº¡y ra ngay láº­p tá»©c
            stream = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                stream=True,
                temperature=0.7
            )

            full_response = ""
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    print(content, end="", flush=True)
                    full_response += content

            messages.append({"role": "assistant", "content": full_response})
            print() 

        except Exception as e:
            print(f"\nâŒ Lá»—i trong quÃ¡ trÃ¬nh chat: {e}")
            print("Gá»£i Ã½: Kiá»ƒm tra log cá»§a vLLM server Ä‘á»ƒ xem cÃ³ lá»—i OOM (Háº¿t bá»™ nhá»›) khÃ´ng.")

if __name__ == "__main__":
    if check_server_connection():
        start_chat()